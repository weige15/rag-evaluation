{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dspy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.chromadb_rm import ChromadbRM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY'] = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['LANGFUSE_SECRET_KEY'] = 'sk-lf-6f3542d6-53e7-4fd2-b417-e6e2fc0512a0'\n",
    "os.environ['LANGFUSE_PUBLIC_KEY'] = 'pk-lf-3d36f7c6-2840-40d1-b129-63e075e24226'\n",
    "os.environ[\"LANGFUSE_HOST\"] = 'https://us.cloud.langfuse.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenerateAnswer(dspy.Signature):\n",
    "    \"\"\"Answer questions given the context\"\"\"\n",
    "\n",
    "    context = dspy.InputField(desc=\"may contain relevant facts\")\n",
    "    question = dspy.InputField()\n",
    "    answer = dspy.OutputField(desc=\"Short factual answer to the question. 1 - 5 words long.\")\n",
    "\n",
    "class RAG(dspy.Module):\n",
    "    def __init__(self, num_passages=5):\n",
    "        super().__init__()\n",
    "        self.retrieve = dspy.Retrieve(k=num_passages)\n",
    "        self.generate_answer = dspy.ChainOfThought(GenerateAnswer)\n",
    "    \n",
    "    def forward(self, question):\n",
    "        context = self.retrieve(question).passages\n",
    "        prediction = self.generate_answer(context=context, question=question)\n",
    "        return dspy.Prediction(context=context, answer=prediction.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup():\n",
    "    \"\"\"\n",
    "    Setup the dsypy and retrieval models\n",
    "    \"\"\"\n",
    "\n",
    "    turbo = dspy.OpenAI(model='gpt-3.5-turbo')\n",
    "\n",
    "    chroma_rm = ChromadbRM(collection_name=\"test-overlap-0\", persist_directory=\"chroma.db\", local_embed_model=\"sentence-transformers/paraphrase-MiniLM-L6-v2\",\n",
    "                                   openai_api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "\n",
    "    dspy.settings.configure(lm=turbo, rm=chroma_rm)\n",
    "    \n",
    "    rag = RAG()\n",
    "\n",
    "    return rag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection Count: 7850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kuotz\\anaconda3\\envs\\langchian2\\lib\\site-packages\\huggingface_hub\\file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\kuotz\\anaconda3\\envs\\langchian2\\lib\\site-packages\\huggingface_hub\\file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "rag = setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read question, ground_truths from ./data/processed/synthetic_dataset.csv\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"./data/processed/synthetic_dataset.csv\")\n",
    "\n",
    "df = df[['question', 'ground_truths']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>ground_truths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Who directed the 2007 production of How to Curse?</td>\n",
       "      <td>['Josie Rourke']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Who starred as \"Jason Tyler\" in the 2006 episo...</td>\n",
       "      <td>['Robert Boulter']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Who was Du Fu's paternal grandfather?</td>\n",
       "      <td>['Du Shenyan']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>When did Du Fu meet Li Bai for the first time?</td>\n",
       "      <td>['Autumn of 744']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What was Du Fu's first official post in the ca...</td>\n",
       "      <td>[\"Registrar of the Right Commandant's office\"]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  Who directed the 2007 production of How to Curse?   \n",
       "1  Who starred as \"Jason Tyler\" in the 2006 episo...   \n",
       "2              Who was Du Fu's paternal grandfather?   \n",
       "3     When did Du Fu meet Li Bai for the first time?   \n",
       "4  What was Du Fu's first official post in the ca...   \n",
       "\n",
       "                                    ground_truths  \n",
       "0                                ['Josie Rourke']  \n",
       "1                              ['Robert Boulter']  \n",
       "2                                  ['Du Shenyan']  \n",
       "3                               ['Autumn of 744']  \n",
       "4  [\"Registrar of the Right Commandant's office\"]  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into train and test\n",
    "train, test = train_test_split(df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the train and test data\n",
    "train.to_csv(\"./data/processed/train_synthetic.csv\", index=False)\n",
    "test.to_csv(\"./data/processed/test_synthetic.csv\", index=False)\n",
    "\n",
    "# load the train and test data\n",
    "train = pd.read_csv(\"./data/processed/train_synthetic.csv\")\n",
    "test = pd.read_csv(\"./data/processed/test_synthetic.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "# Create an empty list to store rows\n",
    "eval_results_rows = []\n",
    "\n",
    "for index, row in test.iterrows():\n",
    "    # Get the question\n",
    "    question = row['question']\n",
    "    # Response from rag\n",
    "    response = rag(question)\n",
    "    # Create a dictionary to represent a row\n",
    "    row_dict = {'question': question, 'contexts': response.context, 'answer': response.answer, 'ground_truths' : row['ground_truths']}\n",
    "    # Append the row dictionary to the list\n",
    "    eval_results_rows.append(row_dict)\n",
    "\n",
    "# Create the df_eval_results DataFrame from the list of rows\n",
    "df_eval_results = pd.DataFrame(eval_results_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>contexts</th>\n",
       "      <th>answer</th>\n",
       "      <th>ground_truths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What was the purpose of Operation Torch, devis...</td>\n",
       "      <td>[. many ships also used a forced draught to ge...</td>\n",
       "      <td>Gain control of North Africa.</td>\n",
       "      <td>['To occupy French North Africa']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the estimated weight of Tres Zapotes M...</td>\n",
       "      <td>[. it has since been moved to the museo comuni...</td>\n",
       "      <td>7.8 tons</td>\n",
       "      <td>['7.8 tons']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Who was widely praised for their performance i...</td>\n",
       "      <td>[american beauty, they gave their top awards t...</td>\n",
       "      <td>Kevin Spacey</td>\n",
       "      <td>['Spacey, Mendes, Ball']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Who won the IWGP Heavyweight Championship on h...</td>\n",
       "      <td>[njcaa heavyweight champion ( 1998 ) north dak...</td>\n",
       "      <td>Lesnar</td>\n",
       "      <td>['Lesnar']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the industrial process for the product...</td>\n",
       "      <td>[= = reactions of oxaziridines = = = = = hydra...</td>\n",
       "      <td>Peroxide process.</td>\n",
       "      <td>['Peroxide process']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>What musical style has Hed PE referred to thei...</td>\n",
       "      <td>[= = musical style = =, . hed pe's music is a ...</td>\n",
       "      <td>G@-@ punk</td>\n",
       "      <td>['G-punk']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>What was the combat efficiency of the 23rd Reg...</td>\n",
       "      <td>[. when the attack finally ceased shortly afte...</td>\n",
       "      <td>38 percent</td>\n",
       "      <td>['38 percent']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>What is the reproductive strategy of most temn...</td>\n",
       "      <td>[evolving from temnospondyls ), . like most li...</td>\n",
       "      <td>External fertilization</td>\n",
       "      <td>['External fertilization']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>What force was greatly feared by nationalists ...</td>\n",
       "      <td>[. on the third day of fighting, 14 august, th...</td>\n",
       "      <td>B-Specials.</td>\n",
       "      <td>['Ulster Special Constabulary']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>What caused the sinking of the fishing vessel ...</td>\n",
       "      <td>[. offshore, a 1 @, @ 040 ton fishing vessel, ...</td>\n",
       "      <td>Typhoon Chan-hom</td>\n",
       "      <td>['Heavy rains and storm.']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>155 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              question  \\\n",
       "0    What was the purpose of Operation Torch, devis...   \n",
       "1    What is the estimated weight of Tres Zapotes M...   \n",
       "2    Who was widely praised for their performance i...   \n",
       "3    Who won the IWGP Heavyweight Championship on h...   \n",
       "4    What is the industrial process for the product...   \n",
       "..                                                 ...   \n",
       "150  What musical style has Hed PE referred to thei...   \n",
       "151  What was the combat efficiency of the 23rd Reg...   \n",
       "152  What is the reproductive strategy of most temn...   \n",
       "153  What force was greatly feared by nationalists ...   \n",
       "154  What caused the sinking of the fishing vessel ...   \n",
       "\n",
       "                                              contexts  \\\n",
       "0    [. many ships also used a forced draught to ge...   \n",
       "1    [. it has since been moved to the museo comuni...   \n",
       "2    [american beauty, they gave their top awards t...   \n",
       "3    [njcaa heavyweight champion ( 1998 ) north dak...   \n",
       "4    [= = reactions of oxaziridines = = = = = hydra...   \n",
       "..                                                 ...   \n",
       "150  [= = musical style = =, . hed pe's music is a ...   \n",
       "151  [. when the attack finally ceased shortly afte...   \n",
       "152  [evolving from temnospondyls ), . like most li...   \n",
       "153  [. on the third day of fighting, 14 august, th...   \n",
       "154  [. offshore, a 1 @, @ 040 ton fishing vessel, ...   \n",
       "\n",
       "                            answer                      ground_truths  \n",
       "0    Gain control of North Africa.  ['To occupy French North Africa']  \n",
       "1                         7.8 tons                       ['7.8 tons']  \n",
       "2                     Kevin Spacey           ['Spacey, Mendes, Ball']  \n",
       "3                           Lesnar                         ['Lesnar']  \n",
       "4                Peroxide process.               ['Peroxide process']  \n",
       "..                             ...                                ...  \n",
       "150                      G@-@ punk                         ['G-punk']  \n",
       "151                     38 percent                     ['38 percent']  \n",
       "152         External fertilization         ['External fertilization']  \n",
       "153                    B-Specials.    ['Ulster Special Constabulary']  \n",
       "154               Typhoon Chan-hom         ['Heavy rains and storm.']  \n",
       "\n",
       "[155 rows x 4 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "# df_eval_results ground_truths to list\n",
    "df_eval_results['ground_truths'] = df_eval_results['ground_truths'].apply(lambda x: ast.literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the df_eval_results DataFrame to a csv file\n",
    "import time\n",
    "EXP_NAME = \"SIMPLE_RAG_NO_OVERLAP\"\n",
    "TIMESTAMP = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "df_eval_results.to_csv('./results/inference_' + EXP_NAME + '_' + TIMESTAMP + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, that we have answers for all the questions, we can evaluate the RAG model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:ragas.validation:passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af406770138142b787c88adf755e4d52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/775 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Runner in Executor raised an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kuotz\\anaconda3\\envs\\langchian2\\lib\\site-packages\\ragas\\executor.py\", line 58, in _aresults\n",
      "    r = await future\n",
      "  File \"c:\\Users\\kuotz\\anaconda3\\envs\\langchian2\\lib\\asyncio\\tasks.py\", line 571, in _wait_for_one\n",
      "    return f.result()  # May raise f.exception().\n",
      "  File \"c:\\Users\\kuotz\\anaconda3\\envs\\langchian2\\lib\\site-packages\\ragas\\executor.py\", line 91, in wrapped_callable_async\n",
      "    return counter, await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\kuotz\\anaconda3\\envs\\langchian2\\lib\\site-packages\\ragas\\metrics\\base.py\", line 91, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\kuotz\\anaconda3\\envs\\langchian2\\lib\\site-packages\\ragas\\metrics\\base.py\", line 87, in ascore\n",
      "    score = await self._ascore(row=row, callbacks=group_cm, is_async=is_async)\n",
      "  File \"c:\\Users\\kuotz\\anaconda3\\envs\\langchian2\\lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 190, in _ascore\n",
      "    assert isinstance(statements, dict), \"Invalid JSON response\"\n",
      "AssertionError: Invalid JSON response\n",
      "ERROR:ragas.executor:Runner in Executor raised an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kuotz\\anaconda3\\envs\\langchian2\\lib\\site-packages\\ragas\\executor.py\", line 58, in _aresults\n",
      "    r = await future\n",
      "  File \"c:\\Users\\kuotz\\anaconda3\\envs\\langchian2\\lib\\asyncio\\tasks.py\", line 571, in _wait_for_one\n",
      "    return f.result()  # May raise f.exception().\n",
      "  File \"c:\\Users\\kuotz\\anaconda3\\envs\\langchian2\\lib\\site-packages\\ragas\\executor.py\", line 91, in wrapped_callable_async\n",
      "    return counter, await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\kuotz\\anaconda3\\envs\\langchian2\\lib\\site-packages\\ragas\\metrics\\base.py\", line 91, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\kuotz\\anaconda3\\envs\\langchian2\\lib\\site-packages\\ragas\\metrics\\base.py\", line 87, in ascore\n",
      "    score = await self._ascore(row=row, callbacks=group_cm, is_async=is_async)\n",
      "  File \"c:\\Users\\kuotz\\anaconda3\\envs\\langchian2\\lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 190, in _ascore\n",
      "    assert isinstance(statements, dict), \"Invalid JSON response\"\n",
      "AssertionError: Invalid JSON response\n",
      "ERROR:ragas.executor:Runner in Executor raised an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kuotz\\anaconda3\\envs\\langchian2\\lib\\site-packages\\ragas\\executor.py\", line 58, in _aresults\n",
      "    r = await future\n",
      "  File \"c:\\Users\\kuotz\\anaconda3\\envs\\langchian2\\lib\\asyncio\\tasks.py\", line 571, in _wait_for_one\n",
      "    return f.result()  # May raise f.exception().\n",
      "  File \"c:\\Users\\kuotz\\anaconda3\\envs\\langchian2\\lib\\site-packages\\ragas\\executor.py\", line 91, in wrapped_callable_async\n",
      "    return counter, await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\kuotz\\anaconda3\\envs\\langchian2\\lib\\site-packages\\ragas\\metrics\\base.py\", line 91, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\kuotz\\anaconda3\\envs\\langchian2\\lib\\site-packages\\ragas\\metrics\\base.py\", line 87, in ascore\n",
      "    score = await self._ascore(row=row, callbacks=group_cm, is_async=is_async)\n",
      "  File \"c:\\Users\\kuotz\\anaconda3\\envs\\langchian2\\lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 190, in _ascore\n",
      "    assert isinstance(statements, dict), \"Invalid JSON response\"\n",
      "AssertionError: Invalid JSON response\n",
      "ERROR:ragas.executor:Runner in Executor raised an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kuotz\\anaconda3\\envs\\langchian2\\lib\\site-packages\\ragas\\executor.py\", line 58, in _aresults\n",
      "    r = await future\n",
      "  File \"c:\\Users\\kuotz\\anaconda3\\envs\\langchian2\\lib\\asyncio\\tasks.py\", line 571, in _wait_for_one\n",
      "    return f.result()  # May raise f.exception().\n",
      "  File \"c:\\Users\\kuotz\\anaconda3\\envs\\langchian2\\lib\\site-packages\\ragas\\executor.py\", line 91, in wrapped_callable_async\n",
      "    return counter, await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\kuotz\\anaconda3\\envs\\langchian2\\lib\\site-packages\\ragas\\metrics\\base.py\", line 91, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\kuotz\\anaconda3\\envs\\langchian2\\lib\\site-packages\\ragas\\metrics\\base.py\", line 87, in ascore\n",
      "    score = await self._ascore(row=row, callbacks=group_cm, is_async=is_async)\n",
      "  File \"c:\\Users\\kuotz\\anaconda3\\envs\\langchian2\\lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 190, in _ascore\n",
      "    assert isinstance(statements, dict), \"Invalid JSON response\"\n",
      "AssertionError: Invalid JSON response\n",
      "ERROR:ragas.executor:Runner in Executor raised an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kuotz\\anaconda3\\envs\\langchian2\\lib\\site-packages\\ragas\\executor.py\", line 58, in _aresults\n",
      "    r = await future\n",
      "  File \"c:\\Users\\kuotz\\anaconda3\\envs\\langchian2\\lib\\asyncio\\tasks.py\", line 571, in _wait_for_one\n",
      "    return f.result()  # May raise f.exception().\n",
      "  File \"c:\\Users\\kuotz\\anaconda3\\envs\\langchian2\\lib\\site-packages\\ragas\\executor.py\", line 91, in wrapped_callable_async\n",
      "    return counter, await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\kuotz\\anaconda3\\envs\\langchian2\\lib\\site-packages\\ragas\\metrics\\base.py\", line 91, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\kuotz\\anaconda3\\envs\\langchian2\\lib\\site-packages\\ragas\\metrics\\base.py\", line 87, in ascore\n",
      "    score = await self._ascore(row=row, callbacks=group_cm, is_async=is_async)\n",
      "  File \"c:\\Users\\kuotz\\anaconda3\\envs\\langchian2\\lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 190, in _ascore\n",
      "    assert isinstance(statements, dict), \"Invalid JSON response\"\n",
      "AssertionError: Invalid JSON response\n",
      "ERROR:ragas.executor:Runner in Executor raised an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kuotz\\anaconda3\\envs\\langchian2\\lib\\site-packages\\ragas\\executor.py\", line 58, in _aresults\n",
      "    r = await future\n",
      "  File \"c:\\Users\\kuotz\\anaconda3\\envs\\langchian2\\lib\\asyncio\\tasks.py\", line 571, in _wait_for_one\n",
      "    return f.result()  # May raise f.exception().\n",
      "  File \"c:\\Users\\kuotz\\anaconda3\\envs\\langchian2\\lib\\site-packages\\ragas\\executor.py\", line 91, in wrapped_callable_async\n",
      "    return counter, await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\kuotz\\anaconda3\\envs\\langchian2\\lib\\site-packages\\ragas\\metrics\\base.py\", line 91, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\kuotz\\anaconda3\\envs\\langchian2\\lib\\site-packages\\ragas\\metrics\\base.py\", line 87, in ascore\n",
      "    score = await self._ascore(row=row, callbacks=group_cm, is_async=is_async)\n",
      "  File \"c:\\Users\\kuotz\\anaconda3\\envs\\langchian2\\lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 190, in _ascore\n",
      "    assert isinstance(statements, dict), \"Invalid JSON response\"\n",
      "AssertionError: Invalid JSON response\n",
      "ERROR:ragas.executor:Runner in Executor raised an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kuotz\\anaconda3\\envs\\langchian2\\lib\\site-packages\\ragas\\executor.py\", line 58, in _aresults\n",
      "    r = await future\n",
      "  File \"c:\\Users\\kuotz\\anaconda3\\envs\\langchian2\\lib\\asyncio\\tasks.py\", line 571, in _wait_for_one\n",
      "    return f.result()  # May raise f.exception().\n",
      "  File \"c:\\Users\\kuotz\\anaconda3\\envs\\langchian2\\lib\\site-packages\\ragas\\executor.py\", line 91, in wrapped_callable_async\n",
      "    return counter, await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\kuotz\\anaconda3\\envs\\langchian2\\lib\\site-packages\\ragas\\metrics\\base.py\", line 91, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\kuotz\\anaconda3\\envs\\langchian2\\lib\\site-packages\\ragas\\metrics\\base.py\", line 87, in ascore\n",
      "    score = await self._ascore(row=row, callbacks=group_cm, is_async=is_async)\n",
      "  File \"c:\\Users\\kuotz\\anaconda3\\envs\\langchian2\\lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 190, in _ascore\n",
      "    assert isinstance(statements, dict), \"Invalid JSON response\"\n",
      "AssertionError: Invalid JSON response\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from ragas.metrics import (\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_relevancy,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    ")\n",
    "\n",
    "ds = Dataset.from_pandas(df_eval_results)\n",
    "\n",
    "\n",
    "try:\n",
    "    result = evaluate(\n",
    "        dataset = ds,\n",
    "        metrics=[\n",
    "            context_relevancy,\n",
    "            context_precision,\n",
    "            context_recall,\n",
    "            faithfulness,\n",
    "            answer_relevancy,\n",
    "        ],\n",
    "        raise_exceptions=False\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ragas.metrics import (\n",
    "#     answer_relevancy,\n",
    "#     faithfulness,\n",
    "#     context_recall,\n",
    "#     context_precision,\n",
    "#     answer_similarity,\n",
    "#     context_relevancy\n",
    "# )\n",
    "# from datasets import Dataset\n",
    "# from ragas import evaluate\n",
    "\n",
    "# ds = Dataset.from_pandas(df_eval_results)\n",
    "\n",
    "# result = evaluate(\n",
    "#     ds,\n",
    "#     metrics=[\n",
    "#         faithfulness,\n",
    "#         answer_relevancy,\n",
    "#         context_relevancy,\n",
    "#         context_recall,\n",
    "#         context_precision\n",
    "#     ],\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context_relevancy': 0.6607, 'context_precision': 0.6197, 'context_recall': 0.6382, 'faithfulness': 0.6828, 'answer_relevancy': 0.6104}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the result\n",
    "result.to_pandas().to_csv('./results/evaluation_' + EXP_NAME + '_' + TIMESTAMP + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>contexts</th>\n",
       "      <th>answer</th>\n",
       "      <th>ground_truths</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>context_relevancy</th>\n",
       "      <th>context_precision</th>\n",
       "      <th>context_recall</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>answer_relevancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What was the purpose of Operation Torch, devis...</td>\n",
       "      <td>[. many ships also used a forced draught to ge...</td>\n",
       "      <td>Gain control of North Africa.</td>\n",
       "      <td>[To occupy French North Africa]</td>\n",
       "      <td>To occupy French North Africa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the estimated weight of Tres Zapotes M...</td>\n",
       "      <td>[. it has since been moved to the museo comuni...</td>\n",
       "      <td>7.8 tons</td>\n",
       "      <td>[7.8 tons]</td>\n",
       "      <td>7.8 tons</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Who was widely praised for their performance i...</td>\n",
       "      <td>[american beauty, they gave their top awards t...</td>\n",
       "      <td>Kevin Spacey</td>\n",
       "      <td>[Spacey, Mendes, Ball]</td>\n",
       "      <td>Spacey, Mendes, Ball</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.843472</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Who won the IWGP Heavyweight Championship on h...</td>\n",
       "      <td>[njcaa heavyweight champion ( 1998 ) north dak...</td>\n",
       "      <td>Lesnar</td>\n",
       "      <td>[Lesnar]</td>\n",
       "      <td>Lesnar</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.905973</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the industrial process for the product...</td>\n",
       "      <td>[= = reactions of oxaziridines = = = = = hydra...</td>\n",
       "      <td>Peroxide process.</td>\n",
       "      <td>[Peroxide process]</td>\n",
       "      <td>Peroxide process</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.927463</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>What musical style has Hed PE referred to thei...</td>\n",
       "      <td>[= = musical style = =, . hed pe's music is a ...</td>\n",
       "      <td>G@-@ punk</td>\n",
       "      <td>[G-punk]</td>\n",
       "      <td>G-punk</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.861600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>What was the combat efficiency of the 23rd Reg...</td>\n",
       "      <td>[. when the attack finally ceased shortly afte...</td>\n",
       "      <td>38 percent</td>\n",
       "      <td>[38 percent]</td>\n",
       "      <td>38 percent</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.971468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>What is the reproductive strategy of most temn...</td>\n",
       "      <td>[evolving from temnospondyls ), . like most li...</td>\n",
       "      <td>External fertilization</td>\n",
       "      <td>[External fertilization]</td>\n",
       "      <td>External fertilization</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.588889</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.916365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>What force was greatly feared by nationalists ...</td>\n",
       "      <td>[. on the third day of fighting, 14 august, th...</td>\n",
       "      <td>B-Specials.</td>\n",
       "      <td>[Ulster Special Constabulary]</td>\n",
       "      <td>Ulster Special Constabulary</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.877489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>What caused the sinking of the fishing vessel ...</td>\n",
       "      <td>[. offshore, a 1 @, @ 040 ton fishing vessel, ...</td>\n",
       "      <td>Typhoon Chan-hom</td>\n",
       "      <td>[Heavy rains and storm.]</td>\n",
       "      <td>Heavy rains and storm.</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.846781</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>155 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              question  \\\n",
       "0    What was the purpose of Operation Torch, devis...   \n",
       "1    What is the estimated weight of Tres Zapotes M...   \n",
       "2    Who was widely praised for their performance i...   \n",
       "3    Who won the IWGP Heavyweight Championship on h...   \n",
       "4    What is the industrial process for the product...   \n",
       "..                                                 ...   \n",
       "150  What musical style has Hed PE referred to thei...   \n",
       "151  What was the combat efficiency of the 23rd Reg...   \n",
       "152  What is the reproductive strategy of most temn...   \n",
       "153  What force was greatly feared by nationalists ...   \n",
       "154  What caused the sinking of the fishing vessel ...   \n",
       "\n",
       "                                              contexts  \\\n",
       "0    [. many ships also used a forced draught to ge...   \n",
       "1    [. it has since been moved to the museo comuni...   \n",
       "2    [american beauty, they gave their top awards t...   \n",
       "3    [njcaa heavyweight champion ( 1998 ) north dak...   \n",
       "4    [= = reactions of oxaziridines = = = = = hydra...   \n",
       "..                                                 ...   \n",
       "150  [= = musical style = =, . hed pe's music is a ...   \n",
       "151  [. when the attack finally ceased shortly afte...   \n",
       "152  [evolving from temnospondyls ), . like most li...   \n",
       "153  [. on the third day of fighting, 14 august, th...   \n",
       "154  [. offshore, a 1 @, @ 040 ton fishing vessel, ...   \n",
       "\n",
       "                            answer                    ground_truths  \\\n",
       "0    Gain control of North Africa.  [To occupy French North Africa]   \n",
       "1                         7.8 tons                       [7.8 tons]   \n",
       "2                     Kevin Spacey           [Spacey, Mendes, Ball]   \n",
       "3                           Lesnar                         [Lesnar]   \n",
       "4                Peroxide process.               [Peroxide process]   \n",
       "..                             ...                              ...   \n",
       "150                      G@-@ punk                         [G-punk]   \n",
       "151                     38 percent                     [38 percent]   \n",
       "152         External fertilization         [External fertilization]   \n",
       "153                    B-Specials.    [Ulster Special Constabulary]   \n",
       "154               Typhoon Chan-hom         [Heavy rains and storm.]   \n",
       "\n",
       "                      ground_truth  context_relevancy  context_precision  \\\n",
       "0    To occupy French North Africa                NaN                NaN   \n",
       "1                         7.8 tons                NaN                NaN   \n",
       "2             Spacey, Mendes, Ball           0.000000           0.843472   \n",
       "3                           Lesnar           1.000000           0.905973   \n",
       "4                 Peroxide process                NaN           0.927463   \n",
       "..                             ...                ...                ...   \n",
       "150                         G-punk           0.375000           0.583333   \n",
       "151                     38 percent           0.272727           1.000000   \n",
       "152         External fertilization           0.750000           0.588889   \n",
       "153    Ulster Special Constabulary           0.272727           1.000000   \n",
       "154         Heavy rains and storm.           0.285714           0.000000   \n",
       "\n",
       "     context_recall  faithfulness  answer_relevancy  \n",
       "0               NaN           NaN               NaN  \n",
       "1          0.000000      0.000000          1.000000  \n",
       "2          0.037037      1.000000          1.000000  \n",
       "3          0.111111      0.000000          0.000000  \n",
       "4          0.428571      0.333333          1.000000  \n",
       "..              ...           ...               ...  \n",
       "150        1.000000      0.000000          0.861600  \n",
       "151        1.000000      1.000000          0.971468  \n",
       "152        1.000000      1.000000          0.916365  \n",
       "153        1.000000      1.000000          0.877489  \n",
       "154        1.000000           NaN          0.846781  \n",
       "\n",
       "[155 rows x 10 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['WANDB_NOTEBOOK_NAME'] = '05_eval_rag.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['WANDB_API_KEY'] = '489eb28b2888d684cef50ac9633d922c62b6c655'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find 05_eval_rag.ipynb.\n",
      "wandb: Currently logged in as: kuotzuwei15 (kuotzuwei15-national-yang-ming-chiao-tung-university). Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\kuotz\\rag-evaluation\\wandb\\run-20240912_003039-i5hqc1lq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kuotzuwei15-national-yang-ming-chiao-tung-university/wikitext-rag-eval/runs/i5hqc1lq' target=\"_blank\">ruby-disco-1</a></strong> to <a href='https://wandb.ai/kuotzuwei15-national-yang-ming-chiao-tung-university/wikitext-rag-eval' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kuotzuwei15-national-yang-ming-chiao-tung-university/wikitext-rag-eval' target=\"_blank\">https://wandb.ai/kuotzuwei15-national-yang-ming-chiao-tung-university/wikitext-rag-eval</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kuotzuwei15-national-yang-ming-chiao-tung-university/wikitext-rag-eval/runs/i5hqc1lq' target=\"_blank\">https://wandb.ai/kuotzuwei15-national-yang-ming-chiao-tung-university/wikitext-rag-eval/runs/i5hqc1lq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0ccaa37ce63419dab7688d867b4df85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.015 MB of 0.026 MB uploaded\\r'), FloatProgress(value=0.5838916292424354, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>answer_relevancy</td><td>▁</td></tr><tr><td>context_precision</td><td>▁</td></tr><tr><td>context_recall</td><td>▁</td></tr><tr><td>context_relevancy</td><td>▁</td></tr><tr><td>faithfulness</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>answer_relevancy</td><td>0.61042</td></tr><tr><td>context_precision</td><td>0.61974</td></tr><tr><td>context_recall</td><td>0.63823</td></tr><tr><td>context_relevancy</td><td>0.66074</td></tr><tr><td>faithfulness</td><td>0.6828</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ruby-disco-1</strong> at: <a href='https://wandb.ai/kuotzuwei15-national-yang-ming-chiao-tung-university/wikitext-rag-eval/runs/i5hqc1lq' target=\"_blank\">https://wandb.ai/kuotzuwei15-national-yang-ming-chiao-tung-university/wikitext-rag-eval/runs/i5hqc1lq</a><br/> View project at: <a href='https://wandb.ai/kuotzuwei15-national-yang-ming-chiao-tung-university/wikitext-rag-eval' target=\"_blank\">https://wandb.ai/kuotzuwei15-national-yang-ming-chiao-tung-university/wikitext-rag-eval</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240912_003039-i5hqc1lq\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.9 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Logging to wandb\n",
    "\n",
    "import wandb\n",
    "\n",
    "# start a new wandb run to track this script\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"wikitext-rag-eval\",\n",
    "    \n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "        \"number_of_questions\": len(ds),\n",
    "        \"comments\": \"Simple QA RAG model with no teleprompter - chunk overlap size 0\",\n",
    "        \"model\": \"RAG\",\n",
    "        \"dataset\": \"Synthetic\",\n",
    "        \"num_passages\": 5,\n",
    "        \"openai_model\": \"gpt-3.5-turbo\",\n",
    "        \"chroma_collection_name\": \"test-overlap-64\",\n",
    "        \"chroma_persist_directory\": \"chroma.db\",\n",
    "        \"chroma_local_embed_model\": \"sentence-transformers/paraphrase-MiniLM-L6-v2\",\n",
    "\n",
    "    }\n",
    ")\n",
    "\n",
    "wandb.log(result)\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's compile the RAG using teleprompters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>ground_truths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the Philippine version of the auto ric...</td>\n",
       "      <td>['Tricycles']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What type of shot could lodge in the hull of a...</td>\n",
       "      <td>['Red hot shot']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>When did Clayton Kershaw debut in the MLB?</td>\n",
       "      <td>['2008']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Who influenced Bacon's use of the \"space frame...</td>\n",
       "      <td>['Alberto Giacometti.']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What was the first studio album released by th...</td>\n",
       "      <td>['Church of Realities']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What was the Appreciation Index figure for \"Th...</td>\n",
       "      <td>['87']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Who was awarded the Medal of Honor for fightin...</td>\n",
       "      <td>['Private First Class Luther H. Story.']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>When did NY 93 become state-maintained between...</td>\n",
       "      <td>['October 1, 1998']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>How many digital downloads had \"Kiss You\" sold...</td>\n",
       "      <td>['207,000']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Who was appointed as the Allied Commander-in-C...</td>\n",
       "      <td>['Lieutenant General Dwight D. Eisenhower']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What is the Philippine version of the auto ric...   \n",
       "1  What type of shot could lodge in the hull of a...   \n",
       "2         When did Clayton Kershaw debut in the MLB?   \n",
       "3  Who influenced Bacon's use of the \"space frame...   \n",
       "4  What was the first studio album released by th...   \n",
       "5  What was the Appreciation Index figure for \"Th...   \n",
       "6  Who was awarded the Medal of Honor for fightin...   \n",
       "7  When did NY 93 become state-maintained between...   \n",
       "8  How many digital downloads had \"Kiss You\" sold...   \n",
       "9  Who was appointed as the Allied Commander-in-C...   \n",
       "\n",
       "                                 ground_truths  \n",
       "0                                ['Tricycles']  \n",
       "1                             ['Red hot shot']  \n",
       "2                                     ['2008']  \n",
       "3                      ['Alberto Giacometti.']  \n",
       "4                      ['Church of Realities']  \n",
       "5                                       ['87']  \n",
       "6     ['Private First Class Luther H. Story.']  \n",
       "7                          ['October 1, 1998']  \n",
       "8                                  ['207,000']  \n",
       "9  ['Lieutenant General Dwight D. Eisenhower']  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "trainset = []\n",
    "for i in range(5):\n",
    "    ex = dspy.Example(\n",
    "        question=train['question'].iloc[i],\n",
    "        answer=ast.literal_eval(train['ground_truths'].iloc[i])[0]\n",
    "    )\n",
    "    ex = ex.with_inputs('question')\n",
    "    trainset.append(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Example({'question': 'What is the Philippine version of the auto rickshaw?', 'answer': 'Tricycles'}) (input_keys={'question'}),\n",
       " Example({'question': 'What type of shot could lodge in the hull of a wooden ship and cause a fire?', 'answer': 'Red hot shot'}) (input_keys={'question'}),\n",
       " Example({'question': 'When did Clayton Kershaw debut in the MLB?', 'answer': '2008'}) (input_keys={'question'}),\n",
       " Example({'question': 'Who influenced Bacon\\'s use of the \"space frame\" in his artwork?', 'answer': 'Alberto Giacometti.'}) (input_keys={'question'}),\n",
       " Example({'question': 'What was the first studio album released by the band?', 'answer': 'Church of Realities'}) (input_keys={'question'})]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:05<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 5 examples in round 0.\n"
     ]
    }
   ],
   "source": [
    "from dspy.teleprompt import BootstrapFewShot\n",
    "\n",
    "# Validation logic: check that the predicted answer is correct.\n",
    "# Also check that the retrieved context does actually contain that answer.\n",
    "def validate_context_and_answer(example, pred, trace=None):\n",
    "    answer_EM = dspy.evaluate.answer_exact_match(example, pred)\n",
    "    answer_PM = dspy.evaluate.answer_passage_match(example, pred)\n",
    "    return answer_EM and answer_PM\n",
    "\n",
    "# Set up a basic teleprompter, which will compile our RAG program.\n",
    "teleprompter = BootstrapFewShot(metric=validate_context_and_answer)\n",
    "\n",
    "# Compile!\n",
    "compiled_rag = teleprompter.compile(RAG(), trainset=trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "def get_evals(dataset, rag):\n",
    "    # Create an empty list to store rows\n",
    "    eval_results_rows = []\n",
    "\n",
    "    for index, row in dataset.iterrows():\n",
    "        # Get the question\n",
    "        question = row['question']\n",
    "        # Response from rag\n",
    "        response = rag(question)\n",
    "        # Create a dictionary to represent a row\n",
    "        row_dict = {'question': question, 'contexts': response.context, 'answer': response.answer, 'ground_truths' : row['ground_truths']}\n",
    "        # Append the row dictionary to the list\n",
    "        eval_results_rows.append(row_dict)\n",
    "\n",
    "    # Create the df_eval_results DataFrame from the list of rows\n",
    "    df_eval_results = pd.DataFrame(eval_results_rows)\n",
    "\n",
    "    # Convert 'ground_truths' column to list\n",
    "    df_eval_results['ground_truths'] = df_eval_results['ground_truths'].apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "    return df_eval_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_eval_results = get_evals(test, compiled_rag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the df_eval_results DataFrame to a csv file\n",
    "import time\n",
    "EXP_NAME = \"COMPILED_RAG_OVERLAP_0\"\n",
    "TIMESTAMP = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "df_eval_results.to_csv('./results/inference_' + EXP_NAME + '_' + TIMESTAMP + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, that we have answers for all the questions, we can evaluate the RAG model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:ragas.validation:passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b0487141e3d45e8b60ee3708d77c36a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/775 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Runner in Executor raised an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kuotz\\anaconda3\\envs\\langchian2\\lib\\site-packages\\ragas\\executor.py\", line 58, in _aresults\n",
      "    r = await future\n",
      "  File \"c:\\Users\\kuotz\\anaconda3\\envs\\langchian2\\lib\\asyncio\\tasks.py\", line 571, in _wait_for_one\n",
      "    return f.result()  # May raise f.exception().\n",
      "  File \"c:\\Users\\kuotz\\anaconda3\\envs\\langchian2\\lib\\site-packages\\ragas\\executor.py\", line 91, in wrapped_callable_async\n",
      "    return counter, await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\kuotz\\anaconda3\\envs\\langchian2\\lib\\site-packages\\ragas\\metrics\\base.py\", line 91, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\kuotz\\anaconda3\\envs\\langchian2\\lib\\site-packages\\ragas\\metrics\\base.py\", line 87, in ascore\n",
      "    score = await self._ascore(row=row, callbacks=group_cm, is_async=is_async)\n",
      "  File \"c:\\Users\\kuotz\\anaconda3\\envs\\langchian2\\lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 190, in _ascore\n",
      "    assert isinstance(statements, dict), \"Invalid JSON response\"\n",
      "AssertionError: Invalid JSON response\n",
      "ERROR:ragas.executor:Runner in Executor raised an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kuotz\\anaconda3\\envs\\langchian2\\lib\\site-packages\\ragas\\executor.py\", line 58, in _aresults\n",
      "    r = await future\n",
      "  File \"c:\\Users\\kuotz\\anaconda3\\envs\\langchian2\\lib\\asyncio\\tasks.py\", line 571, in _wait_for_one\n",
      "    return f.result()  # May raise f.exception().\n",
      "  File \"c:\\Users\\kuotz\\anaconda3\\envs\\langchian2\\lib\\site-packages\\ragas\\executor.py\", line 91, in wrapped_callable_async\n",
      "    return counter, await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\kuotz\\anaconda3\\envs\\langchian2\\lib\\site-packages\\ragas\\metrics\\base.py\", line 91, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\kuotz\\anaconda3\\envs\\langchian2\\lib\\site-packages\\ragas\\metrics\\base.py\", line 87, in ascore\n",
      "    score = await self._ascore(row=row, callbacks=group_cm, is_async=is_async)\n",
      "  File \"c:\\Users\\kuotz\\anaconda3\\envs\\langchian2\\lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 190, in _ascore\n",
      "    assert isinstance(statements, dict), \"Invalid JSON response\"\n",
      "AssertionError: Invalid JSON response\n",
      "ERROR:ragas.executor:Runner in Executor raised an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kuotz\\anaconda3\\envs\\langchian2\\lib\\site-packages\\ragas\\executor.py\", line 58, in _aresults\n",
      "    r = await future\n",
      "  File \"c:\\Users\\kuotz\\anaconda3\\envs\\langchian2\\lib\\asyncio\\tasks.py\", line 571, in _wait_for_one\n",
      "    return f.result()  # May raise f.exception().\n",
      "  File \"c:\\Users\\kuotz\\anaconda3\\envs\\langchian2\\lib\\site-packages\\ragas\\executor.py\", line 91, in wrapped_callable_async\n",
      "    return counter, await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\kuotz\\anaconda3\\envs\\langchian2\\lib\\site-packages\\ragas\\metrics\\base.py\", line 91, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\kuotz\\anaconda3\\envs\\langchian2\\lib\\site-packages\\ragas\\metrics\\base.py\", line 87, in ascore\n",
      "    score = await self._ascore(row=row, callbacks=group_cm, is_async=is_async)\n",
      "  File \"c:\\Users\\kuotz\\anaconda3\\envs\\langchian2\\lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 190, in _ascore\n",
      "    assert isinstance(statements, dict), \"Invalid JSON response\"\n",
      "AssertionError: Invalid JSON response\n",
      "ERROR:ragas.executor:Runner in Executor raised an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kuotz\\anaconda3\\envs\\langchian2\\lib\\site-packages\\ragas\\executor.py\", line 58, in _aresults\n",
      "    r = await future\n",
      "  File \"c:\\Users\\kuotz\\anaconda3\\envs\\langchian2\\lib\\asyncio\\tasks.py\", line 571, in _wait_for_one\n",
      "    return f.result()  # May raise f.exception().\n",
      "  File \"c:\\Users\\kuotz\\anaconda3\\envs\\langchian2\\lib\\site-packages\\ragas\\executor.py\", line 91, in wrapped_callable_async\n",
      "    return counter, await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\kuotz\\anaconda3\\envs\\langchian2\\lib\\site-packages\\ragas\\metrics\\base.py\", line 91, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\kuotz\\anaconda3\\envs\\langchian2\\lib\\site-packages\\ragas\\metrics\\base.py\", line 87, in ascore\n",
      "    score = await self._ascore(row=row, callbacks=group_cm, is_async=is_async)\n",
      "  File \"c:\\Users\\kuotz\\anaconda3\\envs\\langchian2\\lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 190, in _ascore\n",
      "    assert isinstance(statements, dict), \"Invalid JSON response\"\n",
      "AssertionError: Invalid JSON response\n",
      "ERROR:ragas.executor:Runner in Executor raised an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kuotz\\anaconda3\\envs\\langchian2\\lib\\site-packages\\ragas\\executor.py\", line 58, in _aresults\n",
      "    r = await future\n",
      "  File \"c:\\Users\\kuotz\\anaconda3\\envs\\langchian2\\lib\\asyncio\\tasks.py\", line 571, in _wait_for_one\n",
      "    return f.result()  # May raise f.exception().\n",
      "  File \"c:\\Users\\kuotz\\anaconda3\\envs\\langchian2\\lib\\site-packages\\ragas\\executor.py\", line 91, in wrapped_callable_async\n",
      "    return counter, await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\kuotz\\anaconda3\\envs\\langchian2\\lib\\site-packages\\ragas\\metrics\\base.py\", line 91, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\kuotz\\anaconda3\\envs\\langchian2\\lib\\site-packages\\ragas\\metrics\\base.py\", line 87, in ascore\n",
      "    score = await self._ascore(row=row, callbacks=group_cm, is_async=is_async)\n",
      "  File \"c:\\Users\\kuotz\\anaconda3\\envs\\langchian2\\lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 190, in _ascore\n",
      "    assert isinstance(statements, dict), \"Invalid JSON response\"\n",
      "AssertionError: Invalid JSON response\n",
      "ERROR:ragas.executor:Runner in Executor raised an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kuotz\\anaconda3\\envs\\langchian2\\lib\\site-packages\\ragas\\executor.py\", line 58, in _aresults\n",
      "    r = await future\n",
      "  File \"c:\\Users\\kuotz\\anaconda3\\envs\\langchian2\\lib\\asyncio\\tasks.py\", line 571, in _wait_for_one\n",
      "    return f.result()  # May raise f.exception().\n",
      "  File \"c:\\Users\\kuotz\\anaconda3\\envs\\langchian2\\lib\\site-packages\\ragas\\executor.py\", line 91, in wrapped_callable_async\n",
      "    return counter, await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\kuotz\\anaconda3\\envs\\langchian2\\lib\\site-packages\\ragas\\metrics\\base.py\", line 91, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\kuotz\\anaconda3\\envs\\langchian2\\lib\\site-packages\\ragas\\metrics\\base.py\", line 87, in ascore\n",
      "    score = await self._ascore(row=row, callbacks=group_cm, is_async=is_async)\n",
      "  File \"c:\\Users\\kuotz\\anaconda3\\envs\\langchian2\\lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 190, in _ascore\n",
      "    assert isinstance(statements, dict), \"Invalid JSON response\"\n",
      "AssertionError: Invalid JSON response\n",
      "ERROR:ragas.executor:Runner in Executor raised an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kuotz\\anaconda3\\envs\\langchian2\\lib\\site-packages\\ragas\\executor.py\", line 58, in _aresults\n",
      "    r = await future\n",
      "  File \"c:\\Users\\kuotz\\anaconda3\\envs\\langchian2\\lib\\asyncio\\tasks.py\", line 571, in _wait_for_one\n",
      "    return f.result()  # May raise f.exception().\n",
      "  File \"c:\\Users\\kuotz\\anaconda3\\envs\\langchian2\\lib\\site-packages\\ragas\\executor.py\", line 91, in wrapped_callable_async\n",
      "    return counter, await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\kuotz\\anaconda3\\envs\\langchian2\\lib\\site-packages\\ragas\\metrics\\base.py\", line 91, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\kuotz\\anaconda3\\envs\\langchian2\\lib\\site-packages\\ragas\\metrics\\base.py\", line 87, in ascore\n",
      "    score = await self._ascore(row=row, callbacks=group_cm, is_async=is_async)\n",
      "  File \"c:\\Users\\kuotz\\anaconda3\\envs\\langchian2\\lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 190, in _ascore\n",
      "    assert isinstance(statements, dict), \"Invalid JSON response\"\n",
      "AssertionError: Invalid JSON response\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from ragas.metrics import (\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_relevancy,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    ")\n",
    "\n",
    "ds = Dataset.from_pandas(df_eval_results)\n",
    "\n",
    "\n",
    "try:\n",
    "    result = evaluate(\n",
    "        dataset = ds,\n",
    "        metrics=[\n",
    "            faithfulness,\n",
    "            answer_relevancy,\n",
    "            context_relevancy,\n",
    "            context_recall,\n",
    "            context_precision,\n",
    "        ],\n",
    "        raise_exceptions=False\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds = Dataset.from_pandas(df_eval_results)\n",
    "\n",
    "# result = evaluate(\n",
    "#     ds,\n",
    "#     metrics=[\n",
    "#         context_precision,\n",
    "#         faithfulness,\n",
    "#         answer_relevancy,\n",
    "#         context_recall,\n",
    "#         answer_similarity,\n",
    "#         context_relevancy\n",
    "#     ],\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'faithfulness': 0.7160, 'answer_relevancy': 0.6861, 'context_relevancy': 0.5496, 'context_recall': 0.7275, 'context_precision': 0.5440}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the result\n",
    "result.to_pandas().to_csv('./results/evaluation_' + EXP_NAME + '_' + TIMESTAMP + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>contexts</th>\n",
       "      <th>answer</th>\n",
       "      <th>ground_truths</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>answer_relevancy</th>\n",
       "      <th>context_relevancy</th>\n",
       "      <th>context_recall</th>\n",
       "      <th>context_precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What was the purpose of Operation Torch, devis...</td>\n",
       "      <td>[. many ships also used a forced draught to ge...</td>\n",
       "      <td>Military strategy.</td>\n",
       "      <td>[To occupy French North Africa]</td>\n",
       "      <td>To occupy French North Africa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the estimated weight of Tres Zapotes M...</td>\n",
       "      <td>[. it has since been moved to the museo comuni...</td>\n",
       "      <td>7.8 tons.</td>\n",
       "      <td>[7.8 tons]</td>\n",
       "      <td>7.8 tons</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.738929</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Who was widely praised for their performance i...</td>\n",
       "      <td>[american beauty, they gave their top awards t...</td>\n",
       "      <td>Kevin Spacey.</td>\n",
       "      <td>[Spacey, Mendes, Ball]</td>\n",
       "      <td>Spacey, Mendes, Ball</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.915835</td>\n",
       "      <td>0.037037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Who won the IWGP Heavyweight Championship on h...</td>\n",
       "      <td>[njcaa heavyweight champion ( 1998 ) north dak...</td>\n",
       "      <td>Brock Lesnar.</td>\n",
       "      <td>[Lesnar]</td>\n",
       "      <td>Lesnar</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.927463</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the industrial process for the product...</td>\n",
       "      <td>[= = reactions of oxaziridines = = = = = hydra...</td>\n",
       "      <td>Peroxide process.</td>\n",
       "      <td>[Peroxide process]</td>\n",
       "      <td>Peroxide process</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.810523</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>What musical style has Hed PE referred to thei...</td>\n",
       "      <td>[= = musical style = =, . hed pe's music is a ...</td>\n",
       "      <td>G-punk.</td>\n",
       "      <td>[G-punk]</td>\n",
       "      <td>G-punk</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.850167</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>What was the combat efficiency of the 23rd Reg...</td>\n",
       "      <td>[. when the attack finally ceased shortly afte...</td>\n",
       "      <td>38 percent.</td>\n",
       "      <td>[38 percent]</td>\n",
       "      <td>38 percent</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.970747</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>What is the reproductive strategy of most temn...</td>\n",
       "      <td>[evolving from temnospondyls ), . like most li...</td>\n",
       "      <td>External fertilization.</td>\n",
       "      <td>[External fertilization]</td>\n",
       "      <td>External fertilization</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.916365</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.588889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>What force was greatly feared by nationalists ...</td>\n",
       "      <td>[. on the third day of fighting, 14 august, th...</td>\n",
       "      <td>Ulster Special Constabulary (B-Specials)</td>\n",
       "      <td>[Ulster Special Constabulary]</td>\n",
       "      <td>Ulster Special Constabulary</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.877489</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>What caused the sinking of the fishing vessel ...</td>\n",
       "      <td>[. offshore, a 1 @, @ 040 ton fishing vessel, ...</td>\n",
       "      <td>Typhoon Chan-hom.</td>\n",
       "      <td>[Heavy rains and storm.]</td>\n",
       "      <td>Heavy rains and storm.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.846781</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>155 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              question  \\\n",
       "0    What was the purpose of Operation Torch, devis...   \n",
       "1    What is the estimated weight of Tres Zapotes M...   \n",
       "2    Who was widely praised for their performance i...   \n",
       "3    Who won the IWGP Heavyweight Championship on h...   \n",
       "4    What is the industrial process for the product...   \n",
       "..                                                 ...   \n",
       "150  What musical style has Hed PE referred to thei...   \n",
       "151  What was the combat efficiency of the 23rd Reg...   \n",
       "152  What is the reproductive strategy of most temn...   \n",
       "153  What force was greatly feared by nationalists ...   \n",
       "154  What caused the sinking of the fishing vessel ...   \n",
       "\n",
       "                                              contexts  \\\n",
       "0    [. many ships also used a forced draught to ge...   \n",
       "1    [. it has since been moved to the museo comuni...   \n",
       "2    [american beauty, they gave their top awards t...   \n",
       "3    [njcaa heavyweight champion ( 1998 ) north dak...   \n",
       "4    [= = reactions of oxaziridines = = = = = hydra...   \n",
       "..                                                 ...   \n",
       "150  [= = musical style = =, . hed pe's music is a ...   \n",
       "151  [. when the attack finally ceased shortly afte...   \n",
       "152  [evolving from temnospondyls ), . like most li...   \n",
       "153  [. on the third day of fighting, 14 august, th...   \n",
       "154  [. offshore, a 1 @, @ 040 ton fishing vessel, ...   \n",
       "\n",
       "                                       answer  \\\n",
       "0                          Military strategy.   \n",
       "1                                   7.8 tons.   \n",
       "2                               Kevin Spacey.   \n",
       "3                               Brock Lesnar.   \n",
       "4                           Peroxide process.   \n",
       "..                                        ...   \n",
       "150                                   G-punk.   \n",
       "151                               38 percent.   \n",
       "152                   External fertilization.   \n",
       "153  Ulster Special Constabulary (B-Specials)   \n",
       "154                         Typhoon Chan-hom.   \n",
       "\n",
       "                       ground_truths                   ground_truth  \\\n",
       "0    [To occupy French North Africa]  To occupy French North Africa   \n",
       "1                         [7.8 tons]                       7.8 tons   \n",
       "2             [Spacey, Mendes, Ball]           Spacey, Mendes, Ball   \n",
       "3                           [Lesnar]                         Lesnar   \n",
       "4                 [Peroxide process]               Peroxide process   \n",
       "..                               ...                            ...   \n",
       "150                         [G-punk]                         G-punk   \n",
       "151                     [38 percent]                     38 percent   \n",
       "152         [External fertilization]         External fertilization   \n",
       "153    [Ulster Special Constabulary]    Ulster Special Constabulary   \n",
       "154         [Heavy rains and storm.]         Heavy rains and storm.   \n",
       "\n",
       "     faithfulness  answer_relevancy  context_relevancy  context_recall  \\\n",
       "0             NaN               NaN                NaN             NaN   \n",
       "1             NaN               NaN           0.000000        0.738929   \n",
       "2             1.0          0.000000           1.000000        0.915835   \n",
       "3             1.0          1.000000                NaN        0.927463   \n",
       "4             0.0          0.000000           1.000000        0.810523   \n",
       "..            ...               ...                ...             ...   \n",
       "150           0.0          0.850167           0.375000        1.000000   \n",
       "151           1.0          0.970747           0.272727        1.000000   \n",
       "152           1.0          0.916365           0.750000        1.000000   \n",
       "153           1.0          0.877489           0.272727        1.000000   \n",
       "154           0.0          0.846781           0.285714        1.000000   \n",
       "\n",
       "     context_precision  \n",
       "0                  NaN  \n",
       "1             0.000000  \n",
       "2             0.037037  \n",
       "3             0.111111  \n",
       "4             0.428571  \n",
       "..                 ...  \n",
       "150           0.333333  \n",
       "151           1.000000  \n",
       "152           0.588889  \n",
       "153           1.000000  \n",
       "154           0.000000  \n",
       "\n",
       "[155 rows x 10 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\kuotz\\rag-evaluation\\wandb\\run-20240912_005931-0muavdyz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kuotzuwei15-national-yang-ming-chiao-tung-university/wikitext-rag-eval/runs/0muavdyz' target=\"_blank\">effortless-voice-2</a></strong> to <a href='https://wandb.ai/kuotzuwei15-national-yang-ming-chiao-tung-university/wikitext-rag-eval' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kuotzuwei15-national-yang-ming-chiao-tung-university/wikitext-rag-eval' target=\"_blank\">https://wandb.ai/kuotzuwei15-national-yang-ming-chiao-tung-university/wikitext-rag-eval</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kuotzuwei15-national-yang-ming-chiao-tung-university/wikitext-rag-eval/runs/0muavdyz' target=\"_blank\">https://wandb.ai/kuotzuwei15-national-yang-ming-chiao-tung-university/wikitext-rag-eval/runs/0muavdyz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "707aaa099a7c46a198e1e63433459bed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.026 MB uploaded\\r'), FloatProgress(value=0.052009717314487634, max=1…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>answer_relevancy</td><td>▁</td></tr><tr><td>context_precision</td><td>▁</td></tr><tr><td>context_recall</td><td>▁</td></tr><tr><td>context_relevancy</td><td>▁</td></tr><tr><td>faithfulness</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>answer_relevancy</td><td>0.6861</td></tr><tr><td>context_precision</td><td>0.54397</td></tr><tr><td>context_recall</td><td>0.72751</td></tr><tr><td>context_relevancy</td><td>0.54958</td></tr><tr><td>faithfulness</td><td>0.71605</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">effortless-voice-2</strong> at: <a href='https://wandb.ai/kuotzuwei15-national-yang-ming-chiao-tung-university/wikitext-rag-eval/runs/0muavdyz' target=\"_blank\">https://wandb.ai/kuotzuwei15-national-yang-ming-chiao-tung-university/wikitext-rag-eval/runs/0muavdyz</a><br/> View project at: <a href='https://wandb.ai/kuotzuwei15-national-yang-ming-chiao-tung-university/wikitext-rag-eval' target=\"_blank\">https://wandb.ai/kuotzuwei15-national-yang-ming-chiao-tung-university/wikitext-rag-eval</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240912_005931-0muavdyz\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.9 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Logging to wandb\n",
    "\n",
    "# start a new wandb run to track this script\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"wikitext-rag-eval\",\n",
    "     \n",
    "    # track hyperparameters and run metadata(you can see that this is the \"compiled version\")\n",
    "                                             ################################################\n",
    "    config={\n",
    "        \"number_of_questions\": len(ds),\n",
    "        \"comments\": \"Compiled QA RAG model with teleprompter - OVERLAP 0\",\n",
    "        \"model\": \"RAG\",\n",
    "        \"dataset\": \"Synthetic\",\n",
    "        \"num_passages\": 5,\n",
    "        \"openai_model\": \"gpt-3.5-turbo\",\n",
    "        \"chroma_collection_name\": \"test\",\n",
    "        \"chroma_persist_directory\": \"chroma.db\",\n",
    "        \"chroma_local_embed_model\": \"sentence-transformers/paraphrase-MiniLM-L6-v2\",\n",
    "\n",
    "    }\n",
    ")\n",
    "\n",
    "wandb.log(result)\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No Retrieval\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicQA(dspy.Signature):\n",
    "    \"\"\"Answer questions with short factoid answers.\"\"\"\n",
    "\n",
    "    question = dspy.InputField()\n",
    "    answer = dspy.OutputField(desc=\"often between 1 and 5 words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the predictor.\n",
    "generate_answer = dspy.Predict(BasicQA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results_rows = []\n",
    "\n",
    "for index, row in test.iterrows():\n",
    "    # Get the question\n",
    "    question = row['question']\n",
    "    # Response from rag\n",
    "    response = generate_answer(question = question)\n",
    "    # Create a dictionary to represent a row\n",
    "    row_dict = {'question': question, 'answer': response.answer, 'ground_truths' : row['ground_truths']}\n",
    "    # Append the row dictionary to the list\n",
    "    eval_results_rows.append(row_dict)\n",
    "\n",
    "# Create the df_eval_results DataFrame from the list of rows\n",
    "df_eval_results = pd.DataFrame(eval_results_rows)\n",
    "\n",
    "# Convert 'ground_truths' column to list\n",
    "df_eval_results['ground_truths'] = df_eval_results['ground_truths'].apply(lambda x: ast.literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:ragas.validation:passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ebd876b909342c592cc709c37758c71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/155 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from ragas.metrics import (\n",
    "    answer_similarity\n",
    ")\n",
    "\n",
    "ds = Dataset.from_pandas(df_eval_results)\n",
    "\n",
    "\n",
    "try:\n",
    "    result = evaluate(\n",
    "        dataset = ds,\n",
    "        metrics=[\n",
    "            answer_similarity\n",
    "        ],\n",
    "        raise_exceptions=False\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [answer_similarity]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.59it/s]\n",
      "/home/sudhanva/miniconda3/lib/python3.11/site-packages/datasets/table.py:1395: FutureWarning: promote has been superseded by mode='default'.\n",
      "  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]\n",
      "/home/sudhanva/miniconda3/lib/python3.11/site-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by mode='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n"
     ]
    }
   ],
   "source": [
    "# ds = Dataset.from_pandas(df_eval_results)\n",
    "\n",
    "# result = evaluate(\n",
    "#     ds,\n",
    "#     metrics=[\n",
    "#         answer_similarity\n",
    "#     ],\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer_similarity': 0.8686}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_NAME = \"BASIC_QA_OVERLAP_64\"\n",
    "# save the result\n",
    "result.to_pandas().to_csv('./results/evaluation_' + EXP_NAME + '_' + TIMESTAMP + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>ground_truths</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>answer_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What was the purpose of Operation Torch, devis...</td>\n",
       "      <td>To invade North Africa.</td>\n",
       "      <td>[To occupy French North Africa]</td>\n",
       "      <td>To occupy French North Africa</td>\n",
       "      <td>0.928378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the estimated weight of Tres Zapotes M...</td>\n",
       "      <td>about 25 tons</td>\n",
       "      <td>[7.8 tons]</td>\n",
       "      <td>7.8 tons</td>\n",
       "      <td>0.891800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Who was widely praised for their performance i...</td>\n",
       "      <td>Kevin Spacey</td>\n",
       "      <td>[Spacey, Mendes, Ball]</td>\n",
       "      <td>Spacey, Mendes, Ball</td>\n",
       "      <td>0.860952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Who won the IWGP Heavyweight Championship on h...</td>\n",
       "      <td>Brock Lesnar</td>\n",
       "      <td>[Lesnar]</td>\n",
       "      <td>Lesnar</td>\n",
       "      <td>0.952020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the industrial process for the product...</td>\n",
       "      <td>Nazarov cyclization</td>\n",
       "      <td>[Peroxide process]</td>\n",
       "      <td>Peroxide process</td>\n",
       "      <td>0.771584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>What musical style has Hed PE referred to thei...</td>\n",
       "      <td>G-punk</td>\n",
       "      <td>[G-punk]</td>\n",
       "      <td>G-punk</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>What was the combat efficiency of the 23rd Reg...</td>\n",
       "      <td>75%</td>\n",
       "      <td>[38 percent]</td>\n",
       "      <td>38 percent</td>\n",
       "      <td>0.843014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>What is the reproductive strategy of most temn...</td>\n",
       "      <td>External fertilization</td>\n",
       "      <td>[External fertilization]</td>\n",
       "      <td>External fertilization</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>What force was greatly feared by nationalists ...</td>\n",
       "      <td>British Army</td>\n",
       "      <td>[Ulster Special Constabulary]</td>\n",
       "      <td>Ulster Special Constabulary</td>\n",
       "      <td>0.813200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>What caused the sinking of the fishing vessel ...</td>\n",
       "      <td>Capsizing due to rough seas</td>\n",
       "      <td>[Heavy rains and storm.]</td>\n",
       "      <td>Heavy rains and storm.</td>\n",
       "      <td>0.826768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>155 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              question  \\\n",
       "0    What was the purpose of Operation Torch, devis...   \n",
       "1    What is the estimated weight of Tres Zapotes M...   \n",
       "2    Who was widely praised for their performance i...   \n",
       "3    Who won the IWGP Heavyweight Championship on h...   \n",
       "4    What is the industrial process for the product...   \n",
       "..                                                 ...   \n",
       "150  What musical style has Hed PE referred to thei...   \n",
       "151  What was the combat efficiency of the 23rd Reg...   \n",
       "152  What is the reproductive strategy of most temn...   \n",
       "153  What force was greatly feared by nationalists ...   \n",
       "154  What caused the sinking of the fishing vessel ...   \n",
       "\n",
       "                          answer                    ground_truths  \\\n",
       "0        To invade North Africa.  [To occupy French North Africa]   \n",
       "1                  about 25 tons                       [7.8 tons]   \n",
       "2                   Kevin Spacey           [Spacey, Mendes, Ball]   \n",
       "3                   Brock Lesnar                         [Lesnar]   \n",
       "4            Nazarov cyclization               [Peroxide process]   \n",
       "..                           ...                              ...   \n",
       "150                       G-punk                         [G-punk]   \n",
       "151                          75%                     [38 percent]   \n",
       "152       External fertilization         [External fertilization]   \n",
       "153                 British Army    [Ulster Special Constabulary]   \n",
       "154  Capsizing due to rough seas         [Heavy rains and storm.]   \n",
       "\n",
       "                      ground_truth  answer_similarity  \n",
       "0    To occupy French North Africa           0.928378  \n",
       "1                         7.8 tons           0.891800  \n",
       "2             Spacey, Mendes, Ball           0.860952  \n",
       "3                           Lesnar           0.952020  \n",
       "4                 Peroxide process           0.771584  \n",
       "..                             ...                ...  \n",
       "150                         G-punk           1.000000  \n",
       "151                     38 percent           0.843014  \n",
       "152         External fertilization           1.000000  \n",
       "153    Ulster Special Constabulary           0.813200  \n",
       "154         Heavy rains and storm.           0.826768  \n",
       "\n",
       "[155 rows x 5 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\kuotz\\rag-evaluation\\wandb\\run-20240912_010415-cd3i4yq9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kuotzuwei15-national-yang-ming-chiao-tung-university/wikitext-rag-eval/runs/cd3i4yq9' target=\"_blank\">fragrant-firefly-3</a></strong> to <a href='https://wandb.ai/kuotzuwei15-national-yang-ming-chiao-tung-university/wikitext-rag-eval' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kuotzuwei15-national-yang-ming-chiao-tung-university/wikitext-rag-eval' target=\"_blank\">https://wandb.ai/kuotzuwei15-national-yang-ming-chiao-tung-university/wikitext-rag-eval</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kuotzuwei15-national-yang-ming-chiao-tung-university/wikitext-rag-eval/runs/cd3i4yq9' target=\"_blank\">https://wandb.ai/kuotzuwei15-national-yang-ming-chiao-tung-university/wikitext-rag-eval/runs/cd3i4yq9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc66e9d35a304334ac25050a3cd537f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.015 MB of 0.026 MB uploaded\\r'), FloatProgress(value=0.5872857195749565, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>answer_similarity</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>answer_similarity</td><td>0.8686</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fragrant-firefly-3</strong> at: <a href='https://wandb.ai/kuotzuwei15-national-yang-ming-chiao-tung-university/wikitext-rag-eval/runs/cd3i4yq9' target=\"_blank\">https://wandb.ai/kuotzuwei15-national-yang-ming-chiao-tung-university/wikitext-rag-eval/runs/cd3i4yq9</a><br/> View project at: <a href='https://wandb.ai/kuotzuwei15-national-yang-ming-chiao-tung-university/wikitext-rag-eval' target=\"_blank\">https://wandb.ai/kuotzuwei15-national-yang-ming-chiao-tung-university/wikitext-rag-eval</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240912_010415-cd3i4yq9\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.9 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Logging to wandb\n",
    "\n",
    "# start a new wandb run to track this script\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"wikitext-rag-eval\",\n",
    "    \n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "        \"number_of_questions\": len(ds),\n",
    "        \"comments\": \"No RAG model - just basic QA model - OVERLAP 64\",\n",
    "        \"model\": \"RAG\",\n",
    "        \"dataset\": \"Synthetic\",\n",
    "        \"num_passages\": 5,\n",
    "        \"openai_model\": \"gpt-3.5-turbo\",\n",
    "        \"chroma_collection_name\": \"test\",\n",
    "        \"chroma_persist_directory\": \"chroma.db\",\n",
    "        \"chroma_local_embed_model\": \"sentence-transformers/paraphrase-MiniLM-L6-v2\",\n",
    "\n",
    "    }\n",
    ")\n",
    "\n",
    "wandb.log(result)\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
